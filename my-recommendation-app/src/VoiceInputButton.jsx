import React, { useState, useRef } from 'react';
import { buildApiUrl } from './api';

const TRANSLATIONS = {
  ko: {
    voiceInput: 'ğŸ¤ ìŒì„± ì…ë ¥',
    processing: 'ì²˜ë¦¬ ì¤‘...',
    recording: 'â¹ï¸ ë…¹ìŒ ì¤‘ì§€',
    micError: 'ë§ˆì´í¬ ì ‘ê·¼ ê¶Œí•œì´ í•„ìš”í•©ë‹ˆë‹¤.\në¸Œë¼ìš°ì € ì„¤ì •ì—ì„œ ë§ˆì´í¬ ê¶Œí•œì„ í—ˆìš©í•´ì£¼ì„¸ìš”.',
    errorProcess: 'ìŒì„± ì²˜ë¦¬ ì‹¤íŒ¨',
    success: 'âœ… ìŒì„± ì…ë ¥ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!\n\nê° í•­ëª©ì„ í™•ì¸í•˜ê³  í•„ìš”ì‹œ ìˆ˜ì •í•´ì£¼ì„¸ìš”.',
    errorUpload: 'ìŒì„± ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.\n\n',
    errorServer: '\n\nì„œë²„ ìƒíƒœë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.',
  },
  en: {
    voiceInput: 'ğŸ¤ Voice Input',
    processing: 'Processing...',
    recording: 'â¹ï¸ Stop Recording',
    micError: 'Microphone access is required.\nPlease allow microphone permission in your browser settings.',
    errorProcess: 'Voice processing failed',
    success: 'âœ… Voice input complete!\n\nPlease review and modify each field if necessary.',
    errorUpload: 'An error occurred during voice processing.\n\n',
    errorServer: '\n\nPlease check the server status.',
  },
};

/**
 * ìŒì„± ì…ë ¥ ë²„íŠ¼ ì»´í¬ë„ŒíŠ¸
 * ì‚¬ìš©ìì˜ ìŒì„±ì„ ë…¹ìŒí•˜ê³ , ì„œë²„ì—ì„œ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜ í›„ í•„ë“œë³„ë¡œ ë¶„ë¥˜
 */
function VoiceInputButton({ onFieldsReceived, language = 'ko' }) {
  const t = TRANSLATIONS[language] || TRANSLATIONS.ko;
  const [isRecording, setIsRecording] = useState(false);
  const [isProcessing, setIsProcessing] = useState(false);
  const mediaRecorderRef = useRef(null);
  const audioChunksRef = useRef([]);

  /**
   * ë…¹ìŒ ì‹œì‘
   */
  const startRecording = async () => {
    try {
      // ë§ˆì´í¬ ê¶Œí•œ ìš”ì²­
      const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
      const mediaRecorder = new MediaRecorder(stream);
      mediaRecorderRef.current = mediaRecorder;
      audioChunksRef.current = [];

      // ìŒì„± ë°ì´í„° ìˆ˜ì§‘
      mediaRecorder.ondataavailable = (event) => {
        if (event.data.size > 0) {
          audioChunksRef.current.push(event.data);
        }
      };

      // ë…¹ìŒ ì¢…ë£Œ ì‹œ ì„œë²„ë¡œ ì „ì†¡
      mediaRecorder.onstop = async () => {
        const audioBlob = new Blob(audioChunksRef.current, { type: 'audio/webm' });
        await uploadAudio(audioBlob);
        
        // ìŠ¤íŠ¸ë¦¼ ì •ë¦¬
        stream.getTracks().forEach(track => track.stop());
      };

      mediaRecorder.start();
      setIsRecording(true);
      console.log('ë…¹ìŒ ì‹œì‘');
    } catch (error) {
      console.error('ë§ˆì´í¬ ì ‘ê·¼ ì˜¤ë¥˜:', error);
      alert(t.micError);
    }
  };

  /**
   * ë…¹ìŒ ì¤‘ì§€
   */
  const stopRecording = () => {
    if (mediaRecorderRef.current && isRecording) {
      mediaRecorderRef.current.stop();
      setIsRecording(false);
      console.log('ë…¹ìŒ ì¤‘ì§€');
    }
  };

  /**
   * ìŒì„± íŒŒì¼ì„ ì„œë²„ë¡œ ì „ì†¡í•˜ê³  í…ìŠ¤íŠ¸ ë³€í™˜ + í•„ë“œ ë¶„ë¥˜
   */
  const uploadAudio = async (audioBlob) => {
    setIsProcessing(true);
    try {
      const formData = new FormData();
      formData.append('audio_file', audioBlob, 'recording.webm');

      console.log('ìŒì„± íŒŒì¼ ì „ì†¡ ì¤‘...');
      // FormDataëŠ” ì§ì ‘ fetch ì‚¬ìš© (Content-Type í—¤ë”ë¥¼ ìë™ìœ¼ë¡œ ì„¤ì •í•˜ê¸° ìœ„í•´)
      const url = buildApiUrl('/parse-voice-input');
      console.log('ğŸ“¤ ìŒì„± ì…ë ¥ ìš”ì²­:', url);
      
      const response = await fetch(url, {
        method: 'POST',
        body: formData
        // FormDataë¥¼ ì‚¬ìš©í•  ë•ŒëŠ” Content-Type í—¤ë”ë¥¼ ì„¤ì •í•˜ì§€ ì•Šì•„ì•¼ ë¸Œë¼ìš°ì €ê°€ ìë™ìœ¼ë¡œ multipart/form-dataë¥¼ ì„¤ì •í•©ë‹ˆë‹¤
      });

      if (!response.ok) {
        let errorMessage = t.errorProcess;
        try {
          const errorData = await response.json();
          errorMessage = errorData.detail || errorData.message || t.errorProcess;
        } catch (e) {
          // JSON íŒŒì‹± ì‹¤íŒ¨ ì‹œ ìƒíƒœ í…ìŠ¤íŠ¸ ì‚¬ìš©
          errorMessage = response.statusText || `HTTP ${response.status}`;
        }
        console.error('âŒ ìŒì„± ì…ë ¥ ì‹¤íŒ¨:', {
          status: response.status,
          statusText: response.statusText,
          url: url,
          errorMessage: errorMessage
        });
        throw new Error(errorMessage);
      }

      const data = await response.json();
      console.log('âœ… ë³€í™˜ëœ í…ìŠ¤íŠ¸:', data.transcribed_text);
      console.log('âœ… ë¶„ë¥˜ëœ í•„ë“œ:', data.fields);

      // ë¶€ëª¨ ì»´í¬ë„ŒíŠ¸ë¡œ ë°ì´í„° ì „ë‹¬
      if (onFieldsReceived) {
        onFieldsReceived(data.fields, data.transcribed_text);
      }

      alert(t.success);
    } catch (error) {
      console.error('âŒ ìŒì„± ì—…ë¡œë“œ ì˜¤ë¥˜:', error);
      alert(`${t.errorUpload}${error.message}${t.errorServer}`);
    } finally {
      setIsProcessing(false);
    }
  };

  return (
    <div style={{ display: 'inline-block' }}>
      {!isRecording ? (
        <button
          onClick={startRecording}
          disabled={isProcessing}
          style={{
            padding: '10px 20px',
            background: isProcessing 
              ? '#ccc' 
              : 'linear-gradient(135deg, #9370DB 0%, #6A5ACD 50%, #FFD700 100%)',
            color: 'white',
            border: isProcessing ? 'none' : '1px solid #9370DB',
            borderRadius: '10px',
            cursor: isProcessing ? 'not-allowed' : 'pointer',
            fontSize: '15px',
            fontWeight: 'bold',
            display: 'flex',
            alignItems: 'center',
            gap: '8px',
            boxShadow: isProcessing ? 'none' : '0 4px 12px rgba(147, 112, 219, 0.4)',
            transition: 'all 0.3s ease'
          }}
          onMouseEnter={(e) => {
            if (!isProcessing) {
              e.currentTarget.style.background = 'linear-gradient(135deg, #FFD700 0%, #9370DB 100%)';
              e.currentTarget.style.transform = 'translateY(-2px)';
              e.currentTarget.style.boxShadow = '0 6px 16px rgba(147, 112, 219, 0.5)';
            }
          }}
          onMouseLeave={(e) => {
            if (!isProcessing) {
              e.currentTarget.style.background = 'linear-gradient(135deg, #9370DB 0%, #6A5ACD 50%, #FFD700 100%)';
              e.currentTarget.style.transform = 'translateY(0)';
              e.currentTarget.style.boxShadow = '0 4px 12px rgba(147, 112, 219, 0.4)';
            }
          }}
        >
          <span>{isProcessing ? t.processing : t.voiceInput}</span>
        </button>
      ) : (
        <button
          onClick={stopRecording}
          style={{
            padding: '10px 20px',
            background: 'linear-gradient(135deg, #dc2626 0%, #991b1b 100%)',
            color: 'white',
            border: '1px solid #dc2626',
            borderRadius: '10px',
            cursor: 'pointer',
            fontSize: '15px',
            fontWeight: 'bold',
            display: 'flex',
            alignItems: 'center',
            gap: '8px',
            boxShadow: '0 4px 12px rgba(220, 38, 38, 0.4)',
            animation: 'pulse 1.5s infinite'
          }}
        >
          <span style={{ 
            width: '10px', 
            height: '10px', 
            backgroundColor: 'white', 
            borderRadius: '50%',
            animation: 'blink 1s infinite'
          }}></span>
          <span>{t.recording}</span>
        </button>
      )}

      {/* CSS ì• ë‹ˆë©”ì´ì…˜ */}
      <style>{`
        @keyframes pulse {
          0%, 100% {
            opacity: 1;
          }
          50% {
            opacity: 0.8;
          }
        }
        
        @keyframes blink {
          0%, 100% {
            opacity: 1;
          }
          50% {
            opacity: 0.3;
          }
        }
      `}</style>
    </div>
  );
}

export default VoiceInputButton;

